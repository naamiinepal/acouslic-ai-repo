_target_: src.models.BaseModule

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.001
  weight_decay: 0.001
  fused: true

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.3
  patience: 10

net:
  _target_: src.models.components.acouslic_2d2d_model.CustomUnet
  encoder_name: timm-resnest50d_1s4x24d # choose encoder, e.g. mobilenet_v2 or efficientnet-b7
  encoder_weights: imagenet # use `imagenet` pre-trained weights for encoder initialization
  in_channels: 140 # model input channels (1 for gray-scale images, 3 for RGB, etc.)
  classes: 140 # model output channels (number of classes in your dataset)
  decoder_channels: [768, 512, 384, 256, 256]
  segmentation_bias:
    _target_: torch.tensor
    data:
      [
        -7.631,
        -7.4,
        -7.285,
        -7.205,
        -7.063,
        -6.984,
        -6.958,
        -7.018,
        -7.034,
        -6.93,
        -6.815,
        -6.841,
        -6.713,
        -6.462,
        -6.465,
        -6.474,
        -6.303,
        -6.219,
        -6.125,
        -6.084,
        -6.107,
        -6.003,
        -5.891,
        -5.936,
        -5.812,
        -5.733,
        -5.783,
        -5.69,
        -5.634,
        -5.585,
        -5.51,
        -5.536,
        -5.365,
        -5.345,
        -5.297,
        -5.296,
        -5.374,
        -5.338,
        -5.25,
        -5.175,
        -5.117,
        -5.114,
        -5.019,
        -4.917,
        -4.814,
        -4.75,
        -4.71,
        -4.743,
        -4.736,
        -4.768,
        -4.752,
        -4.747,
        -4.755,
        -4.784,
        -4.797,
        -4.743,
        -4.652,
        -4.612,
        -4.638,
        -4.621,
        -4.623,
        -4.633,
        -4.639,
        -4.69,
        -4.726,
        -4.803,
        -4.815,
        -4.861,
        -4.888,
        -4.907,
        -4.937,
        -5.025,
        -5.079,
        -5.099,
        -5.16,
        -5.238,
        -5.352,
        -5.465,
        -5.418,
        -5.358,
        -5.424,
        -5.511,
        -5.666,
        -5.714,
        -5.762,
        -5.843,
        -5.936,
        -5.973,
        -5.997,
        -6.16,
        -6.188,
        -6.293,
        -6.278,
        -6.31,
        -6.363,
        -6.451,
        -6.648,
        -6.787,
        -6.775,
        -6.817,
        -7.133,
        -6.965,
        -7.104,
        -7.48,
        -7.493,
        -7.58,
        -7.422,
        -7.692,
        -7.71,
        -7.727,
        -8.179,
        -8.829,
        -9.052,
        -9.061,
        -8.646,
        -7.799,
        -7.972,
        -7.976,
        -7.748,
        -7.842,
        -7.845,
        -7.842,
        -8.028,
        -8.36,
        -8.845,
        -8.853,
        -8.857,
        -9.477,
        -9.477,
        -9.99e10,
        -9.99e10,
        -9.99e10,
        -9.99e10,
        -9.99e10,
        -9.99e10,
        -9.99e10,
        -9.99e10,
        -9.99e10,
        -9.99e10,
        -9.99e10,
      ]
  classification_bias:
    _target_: torch.tensor
    data:
      [
        -0.005,
        -7.496,
        -5.416,
        -0.006,
        -6.397,
        -5.416,
        -0.007,
        -6.109,
        -5.416,
        -0.007,
        -6.109,
        -5.298,
        -0.009,
        -5.704,
        -5.193,
        -0.01,
        -5.886,
        -4.931,
        -0.011,
        -5.886,
        -4.856,
        -0.01,
        -6.109,
        -4.856,
        -0.01,
        -5.704,
        -5.011,
        -0.011,
        -5.886,
        -4.856,
        -0.011,
        -5.886,
        -4.787,
        -0.011,
        -5.886,
        -4.856,
        -0.012,
        -5.704,
        -4.787,
        -0.015,
        -5.55,
        -4.551,
        -0.015,
        -5.55,
        -4.551,
        -0.014,
        -5.704,
        -4.551,
        -0.017,
        -5.55,
        -4.36,
        -0.018,
        -5.704,
        -4.237,
        -0.02,
        -5.55,
        -4.128,
        -0.021,
        -5.298,
        -4.128,
        -0.021,
        -5.298,
        -4.128,
        -0.024,
        -5.298,
        -3.999,
        -0.027,
        -5.011,
        -3.912,
        -0.026,
        -4.931,
        -3.999,
        -0.029,
        -5.011,
        -3.832,
        -0.03,
        -4.856,
        -3.807,
        -0.029,
        -5.011,
        -3.832,
        -0.031,
        -5.011,
        -3.734,
        -0.033,
        -4.856,
        -3.711,
        -0.035,
        -4.787,
        -3.645,
        -0.038,
        -4.451,
        -3.667,
        -0.036,
        -4.451,
        -3.734,
        -0.042,
        -4.163,
        -3.667,
        -0.043,
        -4.163,
        -3.624,
        -0.045,
        -4.094,
        -3.584,
        -0.045,
        -4.094,
        -3.604,
        -0.041,
        -4.163,
        -3.711,
        -0.041,
        -4.094,
        -3.734,
        -0.043,
        -4.062,
        -3.689,
        -0.047,
        -4.094,
        -3.544,
        -0.048,
        -3.969,
        -3.564,
        -0.047,
        -4.094,
        -3.525,
        -0.054,
        -3.999,
        -3.368,
        -0.06,
        -3.999,
        -3.219,
        -0.067,
        -3.94,
        -3.101,
        -0.071,
        -3.858,
        -3.041,
        -0.075,
        -3.711,
        -3.041,
        -0.073,
        -3.782,
        -3.041,
        -0.073,
        -3.832,
        -3.018,
        -0.07,
        -3.858,
        -3.065,
        -0.073,
        -3.832,
        -3.03,
        -0.072,
        -3.734,
        -3.089,
        -0.071,
        -3.624,
        -3.165,
        -0.069,
        -3.734,
        -3.152,
        -0.067,
        -3.807,
        -3.152,
        -0.071,
        -3.807,
        -3.077,
        -0.077,
        -3.711,
        -2.996,
        -0.079,
        -3.584,
        -3.041,
        -0.076,
        -3.604,
        -3.089,
        -0.075,
        -3.645,
        -3.077,
        -0.073,
        -3.711,
        -3.089,
        -0.071,
        -3.758,
        -3.089,
        -0.069,
        -3.832,
        -3.101,
        -0.067,
        -3.94,
        -3.101,
        -0.063,
        -4.062,
        -3.126,
        -0.058,
        -4.128,
        -3.205,
        -0.057,
        -4.128,
        -3.233,
        -0.055,
        -4.094,
        -3.306,
        -0.053,
        -4.2,
        -3.306,
        -0.052,
        -4.36,
        -3.261,
        -0.051,
        -4.404,
        -3.291,
        -0.048,
        -4.36,
        -3.385,
        -0.044,
        -4.36,
        -3.488,
        -0.044,
        -4.317,
        -3.525,
        -0.041,
        -4.237,
        -3.645,
        -0.037,
        -4.277,
        -3.782,
        -0.034,
        -4.36,
        -3.885,
        -0.031,
        -4.451,
        -3.969,
        -0.033,
        -4.404,
        -3.912,
        -0.034,
        -4.277,
        -3.912,
        -0.033,
        -4.404,
        -3.885,
        -0.03,
        -4.5,
        -3.969,
        -0.027,
        -4.551,
        -4.128,
        -0.024,
        -4.662,
        -4.237,
        -0.023,
        -4.856,
        -4.2,
        -0.021,
        -4.856,
        -4.317,
        -0.019,
        -4.931,
        -4.451,
        -0.019,
        -5.098,
        -4.404,
        -0.019,
        -5.011,
        -4.451,
        -0.016,
        -5.193,
        -4.551,
        -0.016,
        -5.55,
        -4.404,
        -0.015,
        -5.886,
        -4.451,
        -0.015,
        -5.704,
        -4.5,
        -0.013,
        -5.704,
        -4.605,
        -0.013,
        -5.704,
        -4.662,
        -0.012,
        -5.704,
        -4.787,
        -0.01,
        -5.55,
        -5.098,
        -0.008,
        -5.886,
        -5.193,
        -0.008,
        -5.886,
        -5.193,
        -0.008,
        -5.886,
        -5.193,
        -0.007,
        -5.704,
        -5.704,
        -0.008,
        -5.886,
        -5.298,
        -0.007,
        -6.109,
        -5.298,
        -0.005,
        -6.397,
        -5.704,
        -0.005,
        -6.109,
        -5.886,
        -0.004,
        -6.109,
        -6.109,
        -0.005,
        -6.109,
        -5.886,
        -0.004,
        -6.802,
        -5.886,
        -0.004,
        -6.802,
        -5.886,
        -0.004,
        -6.802,
        -5.886,
        -0.003,
        -7.496,
        -6.109,
        -0.002,
        -9.99e10,
        -6.397,
        -0.001,
        -9.99e10,
        -6.802,
        -0.001,
        -9.99e10,
        -6.802,
        -0.002,
        -9.99e10,
        -6.397,
        -0.003,
        -6.802,
        -6.109,
        -0.003,
        -6.802,
        -6.397,
        -0.003,
        -6.802,
        -6.397,
        -0.003,
        -6.397,
        -6.397,
        -0.003,
        -6.397,
        -6.802,
        -0.003,
        -6.397,
        -6.802,
        -0.003,
        -7.496,
        -6.109,
        -0.002,
        -9.99e10,
        -6.109,
        -0.002,
        -9.99e10,
        -6.397,
        -0.001,
        -9.99e10,
        -6.802,
        -0.001,
        -9.99e10,
        -6.802,
        -0.001,
        -9.99e10,
        -6.802,
        -0.001,
        -9.99e10,
        -7.496,
        -0.001,
        -9.99e10,
        -7.496,
        0.,
        -9.99e10,
        -9.99e10,
        0.,
        -9.99e10,
        -9.99e10,
        0.,
        -9.99e10,
        -9.99e10,
        0.,
        -9.99e10,
        -9.99e10,
        0.,
        -9.99e10,
        -9.99e10,
        0.,
        -9.99e10,
        -9.99e10,
        0.,
        -9.99e10,
        -9.99e10,
        0.,
        -9.99e10,
        -9.99e10,
        0.,
        -9.99e10,
        -9.99e10,
        0.,
        -9.99e10,
        -9.99e10,
        0.,
        -9.99e10,
        -9.99e10,
      ]
criterion:
  _target_: src.losses.seg_fs.SegmentationFrameSelectionLoss
  sigmoid: true
  lambda_ce: 0.05
  seg_lambda: 1
  cls_lambda: 1
  cls_weights:
    _target_: torch.tensor
    data: [0.2, 0.45, 0.35]
  seg_weights:
    _target_: torch.tensor
    data: [10]
  batch: true
